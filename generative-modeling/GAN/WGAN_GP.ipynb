{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VANILLA GAN - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '../storage/data/mnist_png/'\n",
    "saveroot = '../storage/GAN_Images/'\n",
    "test_number = 'Test_1'\n",
    "\n",
    "batch_size = 32\n",
    "workers = 4\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Grayscale(1),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "nz = 100\n",
    "\n",
    "lr = 0.0001\n",
    "betas = (0,0.9)\n",
    "Lambda_value = 10\n",
    "\n",
    "num_epochs = 10\n",
    "num_steps = 1000\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torchvision.datasets.ImageFolder(dataroot+'training', transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = torch.utils.data.DataLoader(ds, batch_size, shuffle=True, num_workers=workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for data in (dl):\n",
    "    print(data[0].shape, data[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(nz, 256),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.fc2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.fc3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.fc4 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024, 784),\n",
    "            torch.nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x.shape = batch_size x nz\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(784 , 1024),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1024 , 512),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512 , 256),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Dropout(0.3)\n",
    "        )\n",
    "        self.fc4 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256 , 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (batch_size, 784) or (batch_size, 1, 28, 28)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 784])\n",
      "torch.Size([1024])\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([1, 256])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for params in discriminator.parameters():\n",
    "    print(params.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS AND OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_d = torch.optim.Adam(discriminator.parameters(), lr, betas) ## WGAN-GP ##\n",
    "opt_g = torch.optim.Adam(generator.parameters(), lr, betas) ## WGAN-GP ##\n",
    "criterion = torch.nn.BCELoss() ## WGAN-GP ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = torch.ones((batch_size, 1)).to(device)\n",
    "fake_labels = torch.zeros((batch_size, 1)).to(device) ## WGAN-GP ##\n",
    "fixed_noise = torch.randn(batch_size, nz).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Penalty Loss\n",
    "\n",
    "'''\n",
    "x: real data\n",
    "y: generated data\n",
    "\n",
    "\n",
    "torch.autograd.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False, only_inputs=True, allow_unused=False)\n",
    "Computes and returns the sum of gradients of outputs w.r.t. the inputs.\n",
    "'''\n",
    "def calcGradientPenalty(x, y):\n",
    "\n",
    "  # inspect inputs dimensions\n",
    "  # print(x.shape, y.shape)\n",
    "  # torch.Size([64, 1, 784]) torch.Size([64, 784])\n",
    "  # remove the excess dimension\n",
    "  x = x.view(x.size(0), -1)\n",
    "  \n",
    "\n",
    "  # combine real and generated images\n",
    "  alpha = torch.rand(x.shape).to(device)\n",
    "  interpolated = alpha * x + (1 - alpha) * y\n",
    "  \n",
    "  # convert combination to torch variable with gradients\n",
    "  var_interpolated = torch.autograd.Variable(\n",
    "      interpolated, requires_grad=True).to(device)\n",
    "\n",
    "  # pass combination to the discriminator\n",
    "  outputs = discriminator(var_interpolated)\n",
    "\n",
    "  # find the gradients of the inputs\n",
    "  gradients = torch.autograd.grad(\n",
    "      outputs=outputs,\n",
    "      inputs=var_interpolated,\n",
    "      grad_outputs=torch.ones_like(outputs).to(device),\n",
    "      retain_graph=True,\n",
    "      create_graph=True,\n",
    "      only_inputs=False,\n",
    "      allow_unused=False\n",
    "  )[0]\n",
    "\n",
    "  # calculate the mean norm of the gradients\n",
    "  grad_norm = gradients.norm(2, dim=1).mean()\n",
    "\n",
    "  # calculate the deviation from the value one\n",
    "  loss = (grad_norm - 1) ** 2\n",
    "\n",
    "  # return the gradient penalty\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-TRAIN RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Shape: torch.Size([32, 1, 28, 28])\n",
      "Discriminator Out: torch.Size([32, 1])\n",
      "Loss: tensor(0.6968, device='cuda:0')\n",
      "Fake Shape: torch.Size([32, 784])\n",
      "Discriminator Out: torch.Size([32, 1])\n",
      "Loss: tensor(0.7036, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #REAL BATCH\n",
    "    for xb, _ in dl:\n",
    "        sample = xb.to(device)\n",
    "        break\n",
    "    print(\"Real Shape:\",sample.shape)\n",
    "    out = discriminator(sample)\n",
    "    print(\"Discriminator Out:\",out.shape)\n",
    "    loss = criterion(out, real_labels)\n",
    "    print(\"Loss:\",loss)\n",
    "    #FAKE BATCH\n",
    "    sample = generator(fixed_noise)\n",
    "    print(\"Fake Shape:\",sample.shape)\n",
    "    out = discriminator(sample)\n",
    "    print(\"Discriminator Out:\",out.shape)\n",
    "    loss = criterion(out, real_labels)\n",
    "    print(\"Loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(images):\n",
    "    opt_d.zero_grad()\n",
    "    \n",
    "    real_images = images.to(device)\n",
    "    fake_images = generator(torch.randn(batch_size, nz).to(device))\n",
    "    \n",
    "    real_out = discriminator(real_images)\n",
    "    fake_out = discriminator(fake_images)\n",
    "    \n",
    "    real_loss = criterion(real_out, real_labels)\n",
    "    fake_loss = criterion(fake_out, fake_labels)\n",
    "    gan_loss = fake_loss - real_loss\n",
    "    \n",
    "    ## WGAN-GP ##\n",
    "    gradient_penalty = calcGradientPenalty(real_images, fake_images)\n",
    "    \n",
    "    loss = gan_loss + Lambda_value * gradient_penalty\n",
    "    \n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(images):\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    real_images = images.to(device)\n",
    "    fake_images = generator(torch.randn(batch_size, nz).to(device))\n",
    "    \n",
    "    out = discriminator(fake_images)\n",
    "    \n",
    "    ## WGAN-GP ##\n",
    "    gan_loss = criterion(out, real_labels)\n",
    "    \n",
    "    gradient_penalty = calcGradientPenalty(real_images, fake_images)\n",
    "    \n",
    "    loss = gan_loss + Lambda_value * gradient_penalty\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py:130: UserWarning: only_inputs argument is deprecated and is ignored now (defaults to True). To accumulate gradient for other parts of the graph, please use torch.autograd.backward.\n",
      "  warnings.warn(\"only_inputs argument is deprecated and is ignored now \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 | loss_d: -35.44091796875 | loss_g: 4.295434474945068 | Time: 71 sec\n",
      "2/10 | loss_d: -27.207073211669922 | loss_g: 5.178190231323242 | Time: 145 sec\n",
      "3/10 | loss_d: -27.093839645385742 | loss_g: 5.022879123687744 | Time: 218 sec\n",
      "4/10 | loss_d: -29.01560401916504 | loss_g: 4.832801342010498 | Time: 291 sec\n",
      "5/10 | loss_d: -28.99791145324707 | loss_g: 4.5223588943481445 | Time: 363 sec\n",
      "6/10 | loss_d: -30.0228271484375 | loss_g: 4.130516052246094 | Time: 436 sec\n",
      "7/10 | loss_d: -30.90118980407715 | loss_g: 4.31961727142334 | Time: 509 sec\n",
      "8/10 | loss_d: -31.234460830688477 | loss_g: 4.21400785446167 | Time: 583 sec\n",
      "9/10 | loss_d: -33.00732421875 | loss_g: 4.117537498474121 | Time: 658 sec\n",
      "10/10 | loss_d: -32.86235427856445 | loss_g: 4.160242080688477 | Time: 733 sec\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "loss_D = []\n",
    "loss_G = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch += 1\n",
    "    loss_d = 0.0\n",
    "    loss_g = 0.0\n",
    "    \n",
    "    for i,(images,_) in enumerate(dl):\n",
    "        if i == num_steps:\n",
    "            break\n",
    "            \n",
    "        for _ in range(k):\n",
    "            loss_d += train_discriminator(images)\n",
    "            opt_d.step()\n",
    "        loss_g += train_generator(images)\n",
    "        opt_g.step()\n",
    "    loss_D.append(loss_d / k / i)\n",
    "    loss_G.append(loss_g / i)\n",
    "    \n",
    "    print(f'{epoch}/{num_epochs} | loss_d: {loss_d/k/i} | loss_g: {loss_g/i} | Time: {time.time() - start_time:.0f} sec')\n",
    "    if epoch%10==0:\n",
    "        sample = generator(fixed_noise).detach()\n",
    "        grid = torchvision.utils.make_grid(sample.view(-1, 1, 28, 28), nrow=8, pad_value=1, normalize=False)   \n",
    "        torchvision.utils.save_image(grid.detach().cpu(), os.path.join(saveroot, '20210126_MNIST_WGAN_GP_{}_{}.jpg'.format(str(test_number), str(epoch).zfill(3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(loss_D, label='LOSS D')\n",
    "plt.plot(loss_G, label='LOSS G')\n",
    "plt.legend()\n",
    "plt.savefig('./20210126_MNIST_WGAN_GP_{}'.format(test_number))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE/ LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), './20210126_MNIST_WGAN_GP_G.pt')\n",
    "torch.save(discriminator.state_dict(), './20210126_MNIST_WGAN_GP_D.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
